{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Extreme Data Challenge</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Today's Mission\n",
    "- Your objective is to devise the best possible model to predict successful/default loans using Lending Club loan data.\n",
    "\n",
    "- The training data is 100000 loans labeled either as 1 (successful) or 0 (default). Comes with 33 categorical and numerical features. The testing data is 50000 loans.\n",
    "\n",
    "- A data dictionary file is included as well. It is a table explaining each what each feature means.\n",
    "\n",
    "- You will be judged on how much money you model makes. You will use your model on the testing dataset by making predictions on it and testing them. Assume that each loan is 1000 dollars and the interest rate is 10 percent. That means for every loan you issue that is successfully repaid, you will earn 100 dollars and for every loan you issue that defaults, you will lose 1000 dollars.\n",
    "    \n",
    "        Profit = 100*(Number of True Positives) - 1000*(Number of False Positives) \n",
    "\n",
    "- Use all the tools at your disposal, try all the models we've learned in class. Refer to past class notes for help. Be sure to use modeling evaluating techniques such as ROC curves, confusion matrix, recall/precision, etc.\n",
    "\n",
    "- To optimize model, find the right combination of features and the right model with the right parameters. Get creative!\n",
    "\n",
    "- Remember to use your time wisely, it will go by fast. Communicate amongst yourselves often.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online resources on Lending Club loan data\n",
    "Kaggle Page: https://www.kaggle.com/wendykan/lending-club-loan-data. Make sure to check out the kernels section.\n",
    "\n",
    "Y Hat tutorial (It's in R, but its still useful): http://blog.yhat.com/posts/machine-learning-for-predicting-bad-loans.html\n",
    "\n",
    "Blog tutorial on the data from Kevin Davenport: http://kldavenport.com/lending-club-data-analysis-revisted-with-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports and set pandas options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "pd.set_option(\"max.columns\", 100)\n",
    "pd.set_option(\"max.colwidth\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in training data.\n",
    "# Loan_status column is the target variable. Remember to drop it from df.\n",
    "df = pd.read_csv(\"loan_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data dictionary\n",
    "# Loan S\n",
    "data_dict = pd.read_csv(\"the_data_dictionary.csv\")\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready, Set, Go!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['emp_length']=df['emp_length'].apply(lambda x: x.replace('years', '').replace('year','').replace('+',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['term']=df['term'].apply(lambda x: x.replace('months',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('loan_status').mean().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sb.diverging_palette(220, 10, as_cmap=True)\n",
    "correlations=df1.corr()\n",
    "sb.heatmap(correlations, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 #number of variables for heatmap\n",
    "cols = correlations.nlargest(k, 'loan_status')['loan_status'].index\n",
    "cm = np.corrcoef(df1[cols].values.T)\n",
    "sb.set(font_scale=1.5)\n",
    "hm = sb.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = df1.drop('loan_status',axis=1)\n",
    "# Extract target column 'passed'\n",
    "target_col = df1.loan_status\n",
    "# Show the list of columns\n",
    "print (\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print (\"\\nTarget column: {}\".format(target_col))\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = feature_cols\n",
    "y_all = target_col\n",
    "# Show the feature information by printing the first five rows\n",
    "print (\"\\nFeature values:\")\n",
    "print (X_all.head())\n",
    "print (y_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all_scaled = preprocessing.scale(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all_scaled, y_all, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define your classifiers (models)\n",
    "\n",
    "clf_a = LinearRegression()\n",
    "clf_b = DecisionTreeRegressor(random_state = 0)\n",
    "clf_c = RandomForestRegressor(n_estimators = 5, random_state = 0)\n",
    "clf_d = SVR(kernel = 'rbf')\n",
    "\n",
    "classifiers = (clf_a, clf_b, clf_c, clf_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_a = clf_a.fit(X_train, y_train)\n",
    "pred_probs_clf_a = clf_a.predict(X_test)\n",
    "fpr, tpr, thres = roc_curve(y_test, pred_probs_clf_a)\n",
    "roc_auc_score(y_test, pred_probs_clf_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_b = clf_b.fit(X_train, y_train)\n",
    "pred_probs_clf_b = clf_b.predict(X_test)\n",
    "fpr, tpr, thres = roc_curve(y_test, pred_probs_clf_b)\n",
    "roc_auc_score(y_test, pred_probs_clf_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_c = clf_c.fit(X_train, y_train)\n",
    "pred_probs = clf_c.predict(X_test)\n",
    "fpr, tpr, thres = roc_curve(y_test, pred_probs)\n",
    "roc_auc_score(y_test, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_d = clf_d.fit(X_train, y_train)\n",
    "pred_probs = clf_d.predict(X_test)\n",
    "fpr, tpr, thres = roc_curve(y_test, pred_probs)\n",
    "roc_auc_score(y_test, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can ROC score be improved with GridSearchCV,  regularization and/or Gradient Descent?\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
    "\n",
    "\n",
    "\n",
    "##### Try Lasso, Elastic Net or Ridge Regression\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Time to test your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember: for every loan you issue that is successfully repaid, you will earn 100 dollars and for every loan you issue that defaults, you will lose 1000 dollars.\n",
    "\n",
    "##### Hint 1: use a confusion matrix to calculate your profit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#Profit calculator\n",
    "def profit_calculator(y_true, y_preds):\n",
    "    cm = confusion_matrix(y_true, y_preds)\n",
    "    tp = cm[1,1]\n",
    "    fp = cm[0,1]\n",
    "    return 100*tp - 1000*fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Hint 2: use your calculator such that:\n",
    "profit_calculator(y_test, '...' )\n",
    "\n",
    "'...' being your predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus question\n",
    "\n",
    "### Take your best model and apply PCA\n",
    "#### How does that affect your ROC score ?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
